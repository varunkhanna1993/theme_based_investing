{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import snowflake.connector\n",
    "from snowflake.connector.pandas_tools import write_pandas\n",
    "from datetime import datetime, timedelta\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "SNF_USER = os.getenv('snf_user')\n",
    "SNF_PASSWORD = os.getenv('snf_password')\n",
    "SNF_ACCOUNT = os.getenv('snf_account_name')\n",
    "SNF_WAREHOUSE = os.getenv('snf_warehouse')\n",
    "SNF_DATABASE = os.getenv('snf_db')\n",
    "API_KEY = os.getenv('API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_technical_indicator(symbol, indicator_type, period, start_date, end_date):\n",
    "\n",
    "    base_url = f\"https://financialmodelingprep.com/api/v3/technical_indicator/1day/{symbol}\"\n",
    "    params = {\n",
    "        'type': indicator_type,\n",
    "        'period': period,\n",
    "        'from': start_date,\n",
    "        'to': end_date,\n",
    "        'apikey': API_KEY\n",
    "    }\n",
    "    response = requests.get(base_url, params=params)\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        # Handle both possible response formats\n",
    "        historical_data = data if isinstance(data, list) else data.get('historical', [])\n",
    "        \n",
    "        if historical_data:\n",
    "                   data = response.json()\n",
    "        # Handle both possible response formats\n",
    "        historical_data = data if isinstance(data, list) else data.get('historical', [])\n",
    "        \n",
    "        if historical_data:\n",
    "            df = pd.DataFrame(historical_data)\n",
    "            df['symbol'] = symbol  # Add symbol column\n",
    "            \n",
    "            # The API returns the indicator name as the column regardless of the period,\n",
    "            # so we manually rename it to include the period for clarity.\n",
    "            period_column_name = f\"{indicator_type}_{period}d\"\n",
    "            if indicator_type in df.columns:\n",
    "                df.rename(columns={indicator_type: period_column_name}, inplace=True)\n",
    "            else:\n",
    "                print(f\"The expected indicator '{indicator_type}' is not present in the API response.\")\n",
    "                return pd.DataFrame()\n",
    "\n",
    "            # Filter the DataFrame to include only the date, symbol, and the renamed indicator column\n",
    "            df = df[['date', 'symbol', period_column_name]]\n",
    "            df.columns = [column.upper() for column in df.columns]  # Adjust as necessary to match Snowflake's schema\n",
    "            df['DATE'] = pd.to_datetime(df['DATE'],errors='coerce').dt.date\n",
    "            return df\n",
    "    else:\n",
    "            print(f\"Failed to fetch data for {symbol} with indicator {indicator_type}. Status code: {response.status_code}\")\n",
    "    return pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fetch_technical_indicator('AAPL', 'sma', 5, '2024-02-10', '2024-02-27')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tech_indicators = ['sma', 'ema', 'wma', 'dema', 'tema', 'williams', 'rsi', 'adx', 'standardDeviation']\n",
    "time_period = [5, 10, 15, 20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_and_combine_all_indicators_for_symbol(symbol, tech_indicators, time_periods, start_date, end_date):\n",
    "    # Initialize an empty DataFrame\n",
    "    combined_df = pd.DataFrame()\n",
    "\n",
    "    for indicator in tech_indicators:\n",
    "        for period in time_periods:\n",
    "            df = fetch_technical_indicator(symbol, indicator, period, start_date, end_date)\n",
    "            \n",
    "            # Check if the DataFrame is not empty and contains the expected data\n",
    "            period_column_name = f\"{indicator.upper()}_{period}D\"  # Ensure column name matches expected format\n",
    "            if not df.empty and period_column_name in df.columns:\n",
    "                # If the combined_df is empty, initialize it with the current df\n",
    "                if combined_df.empty:\n",
    "                    combined_df = df\n",
    "                else:\n",
    "                    # Since 'DATE' and 'SYMBOL' are already in the combined_df, ensure they are not duplicated\n",
    "                    df.drop(columns=['SYMBOL'], inplace=True, errors='ignore')\n",
    "                    \n",
    "                    # Merge the new df with the combined_df on 'DATE'\n",
    "                    combined_df = pd.merge(combined_df, df, on=['DATE'], how='outer')\n",
    "\n",
    "    # Ensure the 'DATE' column is correctly formatted as dates\n",
    "    combined_df['DATE'] = pd.to_datetime(combined_df['DATE'], errors='coerce').dt.date\n",
    "\n",
    "    # Sort the DataFrame by 'DATE' to have the data in chronological order\n",
    "    combined_df.sort_values(by='DATE',ascending=False, inplace=True)\n",
    "    combined_df.reset_index(drop = True)\n",
    "    return combined_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## get master stock list from the financial_ratios table instead of calling the api again \n",
    "import snowflake.connector\n",
    "\n",
    "def fetch_master_stock_list():\n",
    "    # Snowflake connection details\n",
    "    ctx = snowflake.connector.connect(\n",
    "        user=SNF_USER,\n",
    "        password=SNF_PASSWORD,\n",
    "        account=SNF_ACCOUNT,\n",
    "        warehouse=SNF_WAREHOUSE,\n",
    "        database=SNF_DATABASE,\n",
    "        schema='PUBLIC'\n",
    "    )\n",
    "    \n",
    "    # Create cursor object\n",
    "    cs = ctx.cursor()\n",
    "    \n",
    "    try:\n",
    "        # Execute the query to fetch distinct stock symbols\n",
    "        cs.execute(\"SELECT DISTINCT symbol FROM stock_analytics.public.financial_ratios\")\n",
    "        \n",
    "        # Fetch all the results\n",
    "        result = cs.fetchall()\n",
    "        \n",
    "        # Extract symbols from the result set\n",
    "        master_stock_list = [row[0] for row in result]\n",
    "        return master_stock_list\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Failed to fetch master stock list: {e}\")\n",
    "        return []\n",
    "    finally:\n",
    "        # Close cursor and connection\n",
    "        cs.close()\n",
    "        ctx.close()\n",
    "\n",
    "# Use the fetched master_stock_list for further processing\n",
    "master_stock_list = fetch_master_stock_list()\n",
    "print(f\"Fetched {len(master_stock_list)} symbols from Snowflake.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### finally upload to snowflake "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import snowflake.connector\n",
    "from snowflake.connector.pandas_tools import write_pandas\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Assuming fetch_and_combine_all_indicators_for_symbol and fetch_master_stock_list are already defined\n",
    "from datetime import date, datetime, timedelta\n",
    "import snowflake.connector\n",
    "from snowflake.connector.pandas_tools import write_pandas\n",
    "\n",
    "def upload_technical_indicators_to_snowflake(master_stock_list):\n",
    "    # Snowflake connection details\n",
    "    ctx = snowflake.connector.connect(\n",
    "        user=SNF_USER,\n",
    "        password=SNF_PASSWORD,\n",
    "        account=SNF_ACCOUNT,\n",
    "        warehouse=SNF_WAREHOUSE,\n",
    "        database=SNF_DATABASE,\n",
    "        schema='PUBLIC'\n",
    "    )\n",
    "\n",
    "    tech_indicators = ['sma', 'ema', 'wma', 'dema', 'tema', 'williams', 'rsi', 'adx', 'standardDeviation']\n",
    "    time_periods = [5, 10, 15, 20]\n",
    "    end_date = date.today()\n",
    "    start_date = end_date - timedelta(days=6*365)\n",
    "\n",
    "    # Loop through each stock in the master_stock_list\n",
    "    for symbol in master_stock_list:\n",
    "        # Check if the ticker's data is already up-to-date\n",
    "        yesterday = (date.today() - timedelta(days=1)).strftime('%Y-%m-%d')\n",
    "        today = date.today().strftime('%Y-%m-%d')\n",
    "        query = f\"SELECT MAX(DATE) FROM STOCK_ANALYTICS.PUBLIC.TECHNICAL_INDICATORS WHERE SYMBOL = '{symbol}'\"\n",
    "        cursor = ctx.cursor()\n",
    "        cursor.execute(query)\n",
    "        result = cursor.fetchone()[0]\n",
    "        max_date = result.strftime('%Y-%m-%d') if result else None\n",
    "\n",
    "        if max_date in [yesterday, today]:\n",
    "            print(f\"Data for {symbol} already up-to-date. Skipping.\")\n",
    "            continue\n",
    "\n",
    "        print(f\"Processing {symbol}\")\n",
    "        try:\n",
    "            combined_indicators_df = fetch_and_combine_all_indicators_for_symbol(symbol, tech_indicators, time_periods, start_date.strftime('%Y-%m-%d'), end_date.strftime('%Y-%m-%d'))\n",
    "\n",
    "            if not combined_indicators_df.empty:\n",
    "                write_pandas(ctx, combined_indicators_df, 'TECHNICAL_INDICATORS')\n",
    "                print(f\"Uploaded indicators for {symbol}\")\n",
    "            else:\n",
    "                print(f\"No data to upload for {symbol}\")\n",
    "        except KeyError as e:\n",
    "            print(f\"KeyError encountered for {symbol}: {e}. Skipping this ticker.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Unexpected error encountered for {symbol}: {e}. Skipping this ticker.\")\n",
    "\n",
    "    ctx.close()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Fetch the master stock list from Snowflake\n",
    "# # master_stock_list = ['AAPL', 'MSFT', 'NVDA']\n",
    "# master_stock_list = fetch_master_stock_list()\n",
    "\n",
    "# # Upload technical indicators for all stocks in the master list\n",
    "\n",
    "# upload_technical_indicators_to_snowflake(master_stock_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
