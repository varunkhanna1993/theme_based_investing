{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import datetime\n",
    "import warnings\n",
    "\n",
    "\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Use os.getenv to get the API key from your .env file\n",
    "API_KEY = os.getenv('API_KEY')\n",
    "BASE_URL = 'https://financialmodelingprep.com/api/v3/'\n",
    "\n",
    "# Function to fetch quarterly financial ratios for a given ticker\n",
    "def fetch_financial_ratios(ticker):\n",
    "    current_year = datetime.datetime.now().year\n",
    "    start_year = current_year - 6\n",
    "\n",
    "    url = f\"https://financialmodelingprep.com/api/v3/ratios/{ticker}?period=quarter&from={start_year}&to={current_year}&apikey={API_KEY}\"\n",
    "    response = requests.get(url)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        # Create DataFrame from the fetched data\n",
    "        df = pd.DataFrame(data)\n",
    "        # Convert the 'date' column to datetime format for filtering\n",
    "        df['date'] = pd.to_datetime(df['date'])\n",
    "        # Filter the DataFrame to ensure it only contains data for the last 6 years\n",
    "        df = df[df['date'].dt.year >= start_year]\n",
    "        return df\n",
    "    else:\n",
    "        print(\"Failed to fetch data:\", response.status_code)\n",
    "        return pd.DataFrame()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### historical s&p constituents. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_historical_changes(api_key):\n",
    "    url = f\"https://financialmodelingprep.com/api/v3/historical/sp500_constituent?apikey={api_key}\"\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        return pd.DataFrame(data)\n",
    "    else:\n",
    "        print(f\"Failed to fetch historical changes: {response.status_code}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "historical_changes = fetch_historical_changes(API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### current s&p consitituents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_current_constituents(api_key):\n",
    "    url = f\"https://financialmodelingprep.com/api/v3/sp500_constituent?apikey={api_key}\"\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        return pd.DataFrame(data)\n",
    "    else:\n",
    "        print(f\"Failed to fetch current constituents: {response.status_code}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "current_constituents = fetch_current_constituents(API_KEY)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### reconstructing constituents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Placeholder function to calculate quarter dates for the last 6 years\n",
    "def calculate_quarter_dates():\n",
    "    today = datetime.date.today()\n",
    "    start_year = today.year - 6\n",
    "    quarters = []\n",
    "    for year in range(start_year, today.year + 1):\n",
    "        for quarter in range(1, 5):\n",
    "            quarter_date = datetime.date(year, 3 * quarter - 2, 1)\n",
    "            if quarter_date < today:\n",
    "                quarters.append(quarter_date)\n",
    "    return quarters\n",
    "\n",
    "# Reconstruct constituents list\n",
    "def reconstruct_constituents(historical_changes, current_constituents):\n",
    "    quarters = calculate_quarter_dates()\n",
    "    constituents_by_quarter = {}\n",
    "    current_list = set(current_constituents['symbol'])\n",
    "\n",
    "    for quarter_end in reversed(quarters):\n",
    "        for _, change in historical_changes.iterrows():\n",
    "            change_date = datetime.datetime.strptime(change['date'], \"%Y-%m-%d\").date()\n",
    "            if change_date > quarter_end:\n",
    "                if change['addedSecurity']:\n",
    "                    current_list.discard(change['symbol'])\n",
    "                if change['removedTicker']:\n",
    "                    current_list.add(change['removedTicker'])\n",
    "        constituents_by_quarter[quarter_end] = current_list.copy()\n",
    "    return constituents_by_quarter\n",
    "\n",
    "constituents_by_quarter = reconstruct_constituents(historical_changes, current_constituents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_stock_set = set()\n",
    "for quarter_end, stocks in constituents_by_quarter.items():\n",
    "    master_stock_set.update(stocks)\n",
    "master_stock_list = list(master_stock_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "612"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(master_stock_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create table and upload to snowflake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import snowflake.connector\n",
    "from snowflake.connector.pandas_tools import write_pandas\n",
    "\n",
    "load_dotenv()\n",
    "SNF_USER = os.getenv('snf_user') \n",
    "SNF_PASSWORD= os.getenv('snf_password')\n",
    "SNF_ACCOUNT= os.getenv('snf_account_name')\n",
    "SNF_WAREHOUSE= os.getenv('snf_warehouse')\n",
    "SNF_DATABASE=os.getenv('snf_db')\n",
    "\n",
    "# Function to upload financial ratios data to Snowflake\n",
    "def upload_financial_ratios_to_snowflake(df, ticker):\n",
    "    # Snowflake connection details\n",
    "    ctx = snowflake.connector.connect(\n",
    "        user=SNF_USER,\n",
    "        password=SNF_PASSWORD,\n",
    "        account=SNF_ACCOUNT,\n",
    "        warehouse=SNF_WAREHOUSE,\n",
    "        database=SNF_DATABASE,\n",
    "        schema='PUBLIC'\n",
    "    )\n",
    "    \n",
    "    # Create cursor object\n",
    "    cs = ctx.cursor()\n",
    "    \n",
    "    # Create schema and table if they don't exist\n",
    "    try:\n",
    "        cs.execute(f\"CREATE SCHEMA IF NOT EXISTS PUBLIC\")\n",
    "        create_table_query = f\"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS FINANCIAL_RATIOS (\n",
    "            symbol VARCHAR,\n",
    "            date DATE,\n",
    "            calendarYear INT,\n",
    "            period VARCHAR,\n",
    "            currentRatio FLOAT,\n",
    "            quickRatio FLOAT,\n",
    "            cashRatio FLOAT,\n",
    "            daysOfSalesOutstanding FLOAT,\n",
    "            daysOfInventoryOutstanding FLOAT,\n",
    "            operatingCycle FLOAT,\n",
    "            daysOfPayablesOutstanding FLOAT,\n",
    "            cashConversionCycle FLOAT,\n",
    "            grossProfitMargin FLOAT,\n",
    "            operatingProfitMargin FLOAT,\n",
    "            pretaxProfitMargin FLOAT,\n",
    "            netProfitMargin FLOAT,\n",
    "            effectiveTaxRate FLOAT,\n",
    "            returnOnAssets FLOAT,\n",
    "            returnOnEquity FLOAT,\n",
    "            returnOnCapitalEmployed FLOAT,\n",
    "            netIncomePerEBT FLOAT,\n",
    "            ebtPerEbit FLOAT,\n",
    "            ebitPerRevenue FLOAT,\n",
    "            debtRatio FLOAT,\n",
    "            debtEquityRatio FLOAT,\n",
    "            longTermDebtToCapitalization FLOAT,\n",
    "            totalDebtToCapitalization FLOAT,\n",
    "            interestCoverage FLOAT,\n",
    "            cashFlowToDebtRatio FLOAT,\n",
    "            companyEquityMultiplier FLOAT,\n",
    "            receivablesTurnover FLOAT,\n",
    "            payablesTurnover FLOAT,\n",
    "            inventoryTurnover FLOAT,\n",
    "            fixedAssetTurnover FLOAT,\n",
    "            assetTurnover FLOAT,\n",
    "            operatingCashFlowPerShare FLOAT,\n",
    "            freeCashFlowPerShare FLOAT,\n",
    "            cashPerShare FLOAT,\n",
    "            payoutRatio FLOAT,\n",
    "            operatingCashFlowSalesRatio FLOAT,\n",
    "            freeCashFlowOperatingCashFlowRatio FLOAT,\n",
    "            cashFlowCoverageRatios FLOAT,\n",
    "            shortTermCoverageRatios FLOAT,\n",
    "            capitalExpenditureCoverageRatio FLOAT,\n",
    "            dividendPaidAndCapexCoverageRatio FLOAT,\n",
    "            dividendPayoutRatio FLOAT,\n",
    "            priceBookValueRatio FLOAT,\n",
    "            priceToBookRatio FLOAT,\n",
    "            priceToSalesRatio FLOAT,\n",
    "            priceEarningsRatio FLOAT,\n",
    "            priceToFreeCashFlowsRatio FLOAT,\n",
    "            priceToOperatingCashFlowsRatio FLOAT,\n",
    "            priceCashFlowRatio FLOAT,\n",
    "            priceEarningsToGrowthRatio FLOAT,\n",
    "            priceSalesRatio FLOAT,\n",
    "            dividendYield FLOAT,\n",
    "            enterpriseValueMultiple FLOAT,\n",
    "            priceFairValue FLOAT\n",
    "            SNAPSHOT_DATE DATE\n",
    "        )\n",
    "        \"\"\"\n",
    "        cs.execute(create_table_query)\n",
    "    except Exception as e:\n",
    "        print(f\"Error creating schema/table: {e}\")\n",
    "    \n",
    "    # Upload DataFrame to Snowflake\n",
    "    try:\n",
    "        write_pandas(ctx, df, 'FINANCIAL_RATIOS')\n",
    "        print(f\"Data for {ticker} uploaded successfully.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error uploading data: {e}\")\n",
    "    \n",
    "    # Close cursor and connection\n",
    "    cs.close()\n",
    "    ctx.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PROCESS ALL STOCKS IN LIST AND UPLOAD TO SNOWFLAKE;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "warnings.filterwarnings('ignore', category=UserWarning)\n",
    "def process_and_upload_snf(stock_list):\n",
    "    load_dotenv() # loading .env variables\n",
    "    ctx = snowflake.connector.connect(\n",
    "    user=SNF_USER,\n",
    "    password=SNF_PASSWORD,\n",
    "    account=\"jlicobf-hb49222\",\n",
    "    warehouse=SNF_WAREHOUSE,\n",
    "    database=SNF_DATABASE,\n",
    "    schema='PUBLIC'\n",
    ")\n",
    "# Process stocks in batches to respect the API limit\n",
    "    batch_size = 100  # API limit\n",
    "    for i in range(0, len(stock_list), batch_size):\n",
    "        batch = stock_list[i:i+batch_size]\n",
    "        for ticker in batch:\n",
    "            try:\n",
    "                df = fetch_financial_ratios(ticker)  # Your function to fetch data\n",
    "                df.columns = [column.upper() for column in df.columns]  # Adjust as necessary to match Snowflake's schema\n",
    "                df['DATE'] = pd.to_datetime(df['DATE'],errors='coerce').dt.date\n",
    "                df['SNAPSHOT_DATE'] = datetime.datetime.now().date() \n",
    "                \n",
    "                if not df.empty:\n",
    "                    write_pandas(ctx, df, 'FINANCIAL_RATIOS')  # Table name in Snowflake\n",
    "                    print(f\"Uploaded data for {ticker}\")\n",
    "                else:\n",
    "                    print(f\"No data fetched for {ticker}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {ticker}: {e}\")\n",
    "        \n",
    "        # Wait for a minute before processing the next batch\n",
    "        if i + batch_size < len(stock_list):  # Avoid sleeping after the last batch\n",
    "            print(\"Waiting to respect API rate limit...\")\n",
    "            time.sleep(60)  # Sleep for 60 seconds\n",
    "\n",
    "    # Close the Snowflake connection\n",
    "    ctx.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
